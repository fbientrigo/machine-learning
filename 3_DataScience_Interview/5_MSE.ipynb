{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Comparing a trained linear regression model with semi-uniform bias\n",
    " Omer trained a linear regression model and tested its performance on a test sample of 500 objects. On 400 of those, the model returned a prediction higher than expected by 0.5, and on the remaining 100, the model returned a prediction lower than expected by 0.7.\n",
    "\n",
    "What is the MSE for his model?\n",
    "\n",
    "Limor claims that the linear regression model wasn't trained correctly, and we can do improve it by changing all the answers by a constant value. What will be her MSE?\n",
    "\n",
    "You can assume that Limor found the smallest error under her constraints.\n",
    "\n",
    "**Return two values - Omer's and Limor's MSE.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivation of answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared error (MSE) is a measure of the quality of a regression model. It is calculated as the average of the squared differences between the predicted and actual values.\n",
    "\n",
    "Omer's model made predictions on 500 objects, with 400 of them having a prediction higher than expected by 0.5, and the remaining 100 having a prediction lower than expected by 0.7. Let's denote the actual values by $y_i$ and the predicted values by $\\hat{y_i}$. Then, the MSE for Omer's model is:\n",
    "\n",
    "$$\\text{MSE}_\\text{Omer} = \\frac{1}{500}\\sum_{i=1}^{500}(\\hat{y_i} - y_i)^2$$\n",
    "\n",
    "For the 400 objects where the prediction was higher than expected by 0.5, the difference between the predicted and actual values is $0.5$, and for the 100 objects where the prediction was lower than expected by 0.7, the difference is $-0.7$. Therefore, we have:\n",
    "\n",
    "$$\\text{MSE}_\\text{Omer} = \\frac{1}{500}\\left[400\\cdot (0.5)^2 + 100\\cdot(-0.7)^2\\right] = 0.298$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.298"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(400 * (0.5)**2 + 100 * (-0.7)**2 ) / 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limor claims that the model can be improved by changing all the answers by a constant value. Let's denote the constant value by $c$. Then, the new predicted values are $\\hat{y_i} + c$, and the MSE for the new model is:\n",
    "\n",
    "$$\\text{MSE}_\\text{Limor} = \\frac{1}{500}\\sum_{i=1}^{500}(\\hat{y_i} + c - y_i)^2$$\n",
    "\n",
    "We want to find the value of $c$ that minimizes the MSE. Taking the derivative of the MSE with respect to $c$ and setting it to zero, we get:\n",
    "\n",
    "$$\\frac{d}{dc}\\text{MSE}_\\text{Limor} = \\frac{2}{500}\\sum_{i=1}^{500}(\\hat{y_i} + c - y_i) = 0$$\n",
    "\n",
    "$$\\frac{d^2}{dc^2}\\text{MSE}_\\text{Limor} = \\frac{2}{500} 500 \\frac{dc}{dc} = 2 > 0$$\n",
    "\n",
    "\n",
    "The second derivative at this point will be positive, so we are at a minimum, then solving for $c$, we get:\n",
    "\n",
    "$$c = \\frac{1}{500}\\sum_{i=1}^{500}(y_i - \\hat{y_i})$$\n",
    "\n",
    "* for 400 data points: $\\hat{y_i} - y_i = 0.5 $\n",
    "* for 100 data points: $\\hat{y_i} - y_i = -0.7 $\n",
    "\n",
    "notice the signs in this case are inversed:\n",
    "\n",
    "$$ c = \\frac{1}{500} [ 400 \\cdot(-0.5) + 100 \\cdot(0.7) ] = -0.26\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most of the bias is caused by overshooting\n",
    "400 * 0.5**2 > 100*0.7**2\n",
    "\n",
    "# that's why the c is negative, to compensate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the propossed bias is c=-0.26\n"
     ]
    }
   ],
   "source": [
    "c = (400 * (-0.5) + 100 * (0.7) ) / 500\n",
    "print(f\"the propossed bias is c={c}\")\n",
    "\n",
    "print(\"Its negative, even if we have 4 times more positive number\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the new predicted values are:\n",
    "\n",
    "$$\\hat{y_i} + c = \\hat{y_i} + \\frac{1}{500}\\sum_{i=1}^{500}(y_i - \\hat{y_i}) = \\hat{y_i} -0.26$$\n",
    "\n",
    "\n",
    "The new MSE is:\n",
    "\n",
    "$$\\text{MSE}_\\text{Limor} = \\frac{1}{500}\\sum_{i=1}^{500}(\\hat{y_i}- y_i  -0.26  )^2$$\n",
    "\n",
    "Remember the inital fact:\n",
    "* for 400 data points: $\\hat{y_i} - y_i = 0.5 $\n",
    "* for 100 data points: $\\hat{y_i} - y_i = -0.7 $\n",
    "\n",
    "$$\\text{MSE}_\\text{Limor} =\n",
    "    \\frac{1}{500}[ 400 \\cdot (0.5 -0.26)^2 + 100\\cdot (-0.7 -0.26)^2 ] \\approx 0.2304$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23039999999999997"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( 400 * (0.5 - 0.26)**2 + 100 * (-0.7 -0.26)**2 ) / 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{MSE}_\\text{Omer} = 0.298$$\n",
    "\n",
    "$$\\text{MSE}_\\text{Limor} \\approx 0.2304$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
